<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-flash.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="实验,信息内容安全," />





  <link rel="alternate" href="/atom.xml" title="神奇小站" type="application/atom+xml" />






<meta property="og:type" content="article">
<meta property="og:title" content="2020-03-25-information-security-exp-1">
<meta property="og:url" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/index.html">
<meta property="og:site_name" content="神奇小站">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200403231659299.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200403140353613.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200327164527042.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402160841956.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402160846431.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402160853276.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402160901843.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402160906535.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402160911519.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402160916924.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402160921928.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402161147165.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402161207830.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402161235158.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402161241441.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402160825591.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402162153169.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402162058589.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402164344702.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402164103572.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402183232902.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402183419220.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402165756192.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402170840117.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402171057952.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402171331034.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402175720833.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402184401030.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402200458302.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402204550930.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402204649960.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402204939305.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402215404788.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402213933616.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402222101748.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402223510719.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402222443363.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402222827956.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402224714359.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402225249765.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402235349247.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200402235614155.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200403123135206.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200403132103024.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200403125234819.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200403125255689.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200403125250180.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200403125309634.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200403125858495.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200403130137855.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200403130202413.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200403130328282.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200403132206171.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200403135744961.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200403133433216.png">
<meta property="og:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200403133608712.png">
<meta property="article:published_time" content="2020-03-25T13:01:15.000Z">
<meta property="article:modified_time" content="2020-04-03T15:17:04.431Z">
<meta property="article:author" content="ColaLinN">
<meta property="article:tag" content="实验">
<meta property="article:tag" content="信息内容安全">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/image-20200403231659299.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"always","offset":12,"b2t":true,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/"/>





  <title>2020-03-25-information-security-exp-1 | 神奇小站</title>
  








<meta name="generator" content="Hexo 4.2.0"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">神奇小站</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">这里总有神奇的东西</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
    
  
  

  <article class="post post-type-normal true" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://colalinn.github.io/2020/03/25/2020-03-25-information-security-exp-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ColaLinN">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="神奇小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">2020-03-25-information-security-exp-1</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-03-25T21:01:15+08:00">
                2020-03-25
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%AE%9E%E9%AA%8C/" itemprop="url" rel="index">
                    <span itemprop="name">实验</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

		  		  
		  
          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  5.5k字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  23分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200403231659299.png" alt="image-20200403231659299"></p>
<a id="more"></a>

<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h1><p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200403140353613.png" alt="image-20200403140353613"></p>
<h1 id="实验环境"><a href="#实验环境" class="headerlink" title="实验环境"></a>实验环境</h1><p>IDE：pycharm</p>
<p>python版本：anacoda-&gt;python3.7</p>
<h1 id="实验1-1-requests库"><a href="#实验1-1-requests库" class="headerlink" title="实验1.1-requests库"></a>实验1.1-requests库</h1><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200327164527042.png" alt="image-20200327164527042"></p>
<p>安装requests库</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install requests</span><br></pre></td></tr></table></figure>

<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402160841956.png" alt="image-20200402160841956"></p>
<h2 id="1-获取状态码"><a href="#1-获取状态码" class="headerlink" title="1.获取状态码"></a>1.获取状态码</h2><p>配置Python环境，使用通用代码框架爬取网站，并获取状态码。 爬取网址请自行选择。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHTMLText</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r=requests.get(url,timeout=<span class="number">30</span>)</span><br><span class="line">        r.raise_for_status()  <span class="comment"># 如果状态不是200，引发error异常</span></span><br><span class="line">        r.encoding=r.apparent_encoding <span class="comment">#获取网页正确的编码格式</span></span><br><span class="line">        <span class="keyword">return</span> r.status_code  <span class="comment">#返回状态码</span></span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"产生异常"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">"__main__"</span>:</span><br><span class="line">    url=<span class="string">"https://www.baidu.com/"</span></span><br><span class="line">    print(getHTMLText(url))</span><br></pre></td></tr></table></figure>

<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402160846431.png" alt="image-20200402160846431"></p>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402160853276.png" alt="image-20200402160853276"></p>
<h2 id="2-使用post-方法"><a href="#2-使用post-方法" class="headerlink" title="2.使用post()方法"></a>2.使用post()方法</h2><p>使用requests库中的post()方法，向<a href="http://httpbin.org/post" target="_blank" rel="noopener">http://httpbin.org/post</a> 增加字段，其中your_name和ID，请使用自己的姓名及学号。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">payload = &#123;<span class="string">'name'</span>: <span class="string">'LFL'</span>, <span class="string">'ID'</span>: <span class="string">'2017301500076'</span>&#125;</span><br><span class="line">r=requests.post(<span class="string">"http://httpbin.org/post"</span>, data=payload)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>

<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402160901843.png" alt="image-20200402160901843"></p>
<h2 id="3-实例1-2-3-4"><a href="#3-实例1-2-3-4" class="headerlink" title="3.实例1/2/3/4"></a>3.实例1/2/3/4</h2><p>完成实例1/2/3/4，其中实例1中的浏览器版本、实例2中搜索关键、实例3中下载图片、实例4 中的IP地址请自行选择。</p>
<h3 id="1-亚马逊网站商品页面爬取"><a href="#1-亚马逊网站商品页面爬取" class="headerlink" title="1-亚马逊网站商品页面爬取"></a>1-亚马逊网站商品页面爬取</h3><p>直接访问亚马逊会返回503访问异常错误</p>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402160906535.png" alt="image-20200402160906535"></p>
<p>所以在头部加上浏览器版本</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">hd=&#123;<span class="string">'user-agent'</span>:<span class="string">'Chrome/66.0'</span>&#125;</span><br><span class="line"><span class="comment"># r=requests.request('post','https://www.amazon.com/',headers=hd)</span></span><br><span class="line">r=requests.get(<span class="string">"https://www.amazon.com"</span>,headers=hd)</span><br><span class="line">print(r.status_code)</span><br></pre></td></tr></table></figure>

<p>返回码200正确</p>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402160911519.png" alt="image-20200402160911519"></p>
<h3 id="2-搜索引擎搜索关键词提交"><a href="#2-搜索引擎搜索关键词提交" class="headerlink" title="2-搜索引擎搜索关键词提交"></a>2-搜索引擎搜索关键词提交</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">instance_2</span><span class="params">()</span>:</span></span><br><span class="line">    keyword = <span class="string">"WHU"</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        kv = &#123;<span class="string">'wd'</span>: keyword,<span class="string">'user-agent'</span>:<span class="string">'Chrome/66.0'</span>&#125;</span><br><span class="line">        r = requests.get(<span class="string">"http://www.baidu.com/s"</span>,params=kv)</span><br><span class="line">        print(r.request.url)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        print(r.text[<span class="number">1</span>:<span class="number">1000</span>])</span><br><span class="line">    <span class="comment"># 结果太长，打印前1000个字符</span></span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        print(<span class="string">"爬取失败"</span>)</span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">"__main__"</span>:</span><br><span class="line">    instance_2()</span><br></pre></td></tr></table></figure>

<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402160916924.png" alt="image-20200402160916924"></p>
<h3 id="3-网络图片的爬取和存储"><a href="#3-网络图片的爬取和存储" class="headerlink" title="3-网络图片的爬取和存储"></a>3-网络图片的爬取和存储</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">instance_3</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">import</span> requests</span><br><span class="line">    <span class="keyword">import</span> os  <span class="comment"># OS库提供了使用各种操作系统功能的接口。</span></span><br><span class="line">    url = <span class="string">"https://colalinn.github.io/2020/02/28/2020-02-28-algorithm-class/image-20200228174457509.png"</span></span><br><span class="line">    root = <span class="string">""</span></span><br><span class="line">    path = root + url.split(<span class="string">'/'</span>)[<span class="number">-1</span>]</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(root):</span><br><span class="line">            print(<span class="string">"就是py下的目录啦！"</span>)</span><br><span class="line">            <span class="comment"># os.mkdir(root)  # 用于以数字权限模式创建目录</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(path):</span><br><span class="line">            print(<span class="string">"客官文件不存在哦,我们保存一下！"</span>)</span><br><span class="line">            r = requests.get(url)</span><br><span class="line">            <span class="keyword">with</span> open(path, <span class="string">'wb'</span>)<span class="keyword">as</span> f:</span><br><span class="line">                f.write(r.content)</span><br><span class="line">                f.close()</span><br><span class="line">                print(<span class="string">"文件保存成功"</span>)</span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># 写代码时注意缩进</span></span><br><span class="line">            print(<span class="string">"文件已存在"</span>)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        print(<span class="string">"爬取失败"</span>)</span><br><span class="line">   </span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">"__main__"</span>:</span><br><span class="line">    instance_3()</span><br></pre></td></tr></table></figure>

<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402160921928.png" alt="image-20200402160921928"></p>
<h3 id="4-ip地址的查询"><a href="#4-ip地址的查询" class="headerlink" title="4-ip地址的查询"></a>4-ip地址的查询</h3><p>原ppt链接的网站会有一个弹窗，这里暂不改动</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">instance_4</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">import</span> requests</span><br><span class="line">    <span class="comment"># url="http://www.ip138.com/ips138.asp?ip=" #这个链接不能用了</span></span><br><span class="line">    url = <span class="string">"https://ipchaxun.com/"</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        hd = &#123;<span class="string">'user-agent'</span>: <span class="string">'Chrome/66.0'</span>&#125;</span><br><span class="line">        r = requests.get(url + <span class="string">'220.181.38.148'</span>,headers=hd)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line">        print(r.text[<span class="number">1900</span>:<span class="number">2400</span>])  <span class="comment"># 输出最后2000个字符</span></span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        print(<span class="string">"爬取失败"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">"__main__"</span>:</span><br><span class="line">    instance_4()</span><br></pre></td></tr></table></figure>

<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402161147165.png" alt="image-20200402161147165"></p>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402161207830.png" alt="image-20200402161207830"></p>
<h1 id="实验1-2-BeautifulSoup库"><a href="#实验1-2-BeautifulSoup库" class="headerlink" title="实验1.2-BeautifulSoup库"></a>实验1.2-BeautifulSoup库</h1><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>BeautifulSoup 是一个可以从HTML或XML文件中提取数据的Python库.它能够通过转换器实现文档导航、查找、修改。</p>
<p>安装        </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install beautifulsoup4</span><br></pre></td></tr></table></figure>

<p>解析器</p>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402161235158.png" alt="image-20200402161235158"></p>
<h2 id="实验要求"><a href="#实验要求" class="headerlink" title="实验要求"></a>实验要求</h2><ul>
<li>参考实例2，爬取百度搜索风云榜 <a href="http://top.baidu.com/" target="_blank" rel="noopener">http://top.baidu.com/</a> 任一榜单，搜索结果按顺序逐行输出（含编号），榜单自选。</li>
<li>自行编码完成实例3，并回答思考题。</li>
<li>爬取当当图书排行榜（榜单自选），格式：爬取结果包含但不限于[排名 书名 作者]， 注意输出格式对齐。</li>
</ul>
<h2 id="1-爬取百度搜索风云榜"><a href="#1-爬取百度搜索风云榜" class="headerlink" title="1-爬取百度搜索风云榜"></a>1-爬取百度搜索风云榜</h2><p>使用审查可以看到百度搜索风云榜的标签都是a标签，属性是“list-title”</p>
<p>所以我们使用以下方式即可获取所有人物串</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">soup.find_all(<span class="string">'a'</span>, <span class="string">'list-title'</span>)</span><br></pre></td></tr></table></figure>

<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402161241441.png" alt="image-20200402161241441"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">instance_2</span><span class="params">()</span>:</span></span><br><span class="line">    r = requests.get(<span class="string">"http://top.baidu.com/buzz?b=257&amp;fr=topboards"</span>)</span><br><span class="line">    r.encoding = r.apparent_encoding</span><br><span class="line">    demo = r.text</span><br><span class="line">    soup = BeautifulSoup(demo, <span class="string">'html.parser'</span>)</span><br><span class="line">    ulist = []</span><br><span class="line">    <span class="keyword">for</span> tag <span class="keyword">in</span> soup.find_all(<span class="string">'a'</span>, <span class="string">'list-title'</span>):</span><br><span class="line">        ulist.append(tag.string)  <span class="comment"># Xlist.append()在列表X尾部增加一个新的元素</span></span><br><span class="line">        print(ulist.index(tag.string) + <span class="number">1</span>, ulist[ulist.index(tag.string)])</span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">"__main__"</span>:</span><br><span class="line">    <span class="comment"># instance_1()</span></span><br><span class="line">    instance_2()</span><br></pre></td></tr></table></figure>

<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402160825591.png" alt="image-20200402160825591"></p>
<h2 id="2-爬取中国大学排行榜-扩展"><a href="#2-爬取中国大学排行榜-扩展" class="headerlink" title="2-爬取中国大学排行榜+扩展"></a>2-爬取中国大学排行榜+扩展</h2><p>一开始我们的代码如下，</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fillUnivList</span><span class="params">(ulist, html)</span>:</span></span><br><span class="line">    soup = BeautifulSoup(html, <span class="string">"html.parser"</span>)</span><br><span class="line">    <span class="keyword">for</span> tr <span class="keyword">in</span> soup.find(<span class="string">'tbody'</span>).children:</span><br><span class="line">        <span class="keyword">if</span> isinstance(tr, bs4.element.Tag):</span><br><span class="line">            tds = tr(<span class="string">'td'</span>)</span><br><span class="line">            ulist.append([tr.td.string, tds[<span class="number">1</span>].string, tds[<span class="number">3</span>].string])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printUnivList</span><span class="params">(ulist, num)</span>:</span></span><br><span class="line">    print(<span class="string">"&#123;:^10&#125;\t&#123;:^6&#125;\t&#123;:^10&#125;"</span>.format(<span class="string">"排名"</span>, <span class="string">"学校名称"</span>, <span class="string">"总分"</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num):</span><br><span class="line">        u = ulist[i]</span><br><span class="line">        print(<span class="string">"&#123;:^10&#125;\t&#123;:^6&#125;\t&#123;:^10&#125;"</span>.format(u[<span class="number">0</span>], u[<span class="number">1</span>], u[<span class="number">2</span>]))</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">instance_3</span><span class="params">()</span>:</span></span><br><span class="line">    uinfo = []</span><br><span class="line">    url = <span class="string">'http://www.zuihaodaxue.cn/zuihaodaxuepaiming2016.html'</span></span><br><span class="line">    html = getHTMLText(url)</span><br><span class="line">    fillUnivList(uinfo, html)</span><br><span class="line">    printUnivList(uinfo, <span class="number">20</span>)  <span class="comment"># 20 univs</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">"__main__"</span>:</span><br><span class="line">    instance_3()</span><br></pre></td></tr></table></figure>

<p>结果是不对齐的，这是因为当中文字符宽度不够时，采用西文字符填充；中西文字符占用宽度不同</p>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402162153169.png" alt="image-20200402162153169"></p>
<p>之后我们将printUnivList函数改成如下，排列对齐了</p>
<p>tplt为定义的输出格式模板变量：</p>
<ul>
<li>^代表居中</li>
<li>4/12/10代表输出宽度（当输出数据超过该数字时，以实际输出为准）</li>
<li>{3}代表打印输出时，我们使用chr(12288)中文空格对齐（全角Unicode空格）</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printUnivList_A</span><span class="params">(ulist, num)</span>:</span></span><br><span class="line">    tplt = <span class="string">"&#123;0:^4&#125;\t&#123;1:&#123;3&#125;^12&#125;\t&#123;2:^10&#125;"</span></span><br><span class="line">    print(tplt.format(<span class="string">"排名"</span>, <span class="string">"学校名称"</span>, <span class="string">"总分"</span>, chr(<span class="number">12288</span>)))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num):</span><br><span class="line">        u = ulist[i]</span><br><span class="line">        print(tplt.format(u[<span class="number">0</span>], u[<span class="number">1</span>], u[<span class="number">2</span>], chr(<span class="number">12288</span>)))</span><br></pre></td></tr></table></figure>

<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402162058589.png" alt="image-20200402162058589"></p>
<h3 id="扩展1-url改为2017"><a href="#扩展1-url改为2017" class="headerlink" title="扩展1-url改为2017"></a>扩展1-url改为2017</h3><p>将实例2中url改为软科中国最好大学排名2017？</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">url = <span class="string">'http://www.zuihaodaxue.cn/zuihaodaxuepaiming2017.html'</span></span><br></pre></td></tr></table></figure>

<p>会报错 <code>排名</code>找不到</p>
<p>我们将ulist打印出来，发现排名为none，说明没有获取到排名的值</p>
<p>而我在chrome上审查，2017和2016的排名处格式是相同的</p>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402164344702.png" alt="image-20200402164344702"></p>
<p>而在代码中使用<code>soup.prettify()</code>打印出来代码后发现排名处格式没有<code>&lt;td&gt;&lt;/td&gt;</code>的闭合，这里估计是用了javascript渲染时做了手脚使得td标签变了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">soup = BeautifulSoup(html, <span class="string">"html.parser"</span>)</span><br><span class="line">print(soup.prettify())</span><br></pre></td></tr></table></figure>

<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402164103572.png" alt="image-20200402164103572"></p>
<p>由图上可知，第一个td标签包含了所有内容，包括排名，所以无法通过<code>tds[0]</code>找到</p>
<p>解决方案：</p>
<p>使用contends</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tds[<span class="number">0</span>].contents[<span class="number">0</span>]   <span class="comment">#这个就是排名了</span></span><br><span class="line">tds[<span class="number">0</span>].get_text(<span class="string">" "</span>).split(<span class="string">" "</span>)[<span class="number">0</span>]  <span class="comment">#这个也可以,get_text()清空所有html标签元素</span></span><br></pre></td></tr></table></figure>

<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402183232902.png" alt="image-20200402183232902"></p>
<p>总代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fillUnivList</span><span class="params">(ulist, html)</span>:</span></span><br><span class="line">    soup = BeautifulSoup(html, <span class="string">"html.parser"</span>)</span><br><span class="line">    <span class="comment"># print(soup.prettify())</span></span><br><span class="line">    <span class="keyword">for</span> tr <span class="keyword">in</span> soup.find(<span class="string">'tbody'</span>).children:</span><br><span class="line">        <span class="keyword">if</span> isinstance(tr, bs4.element.Tag):</span><br><span class="line">            tds = tr(<span class="string">'td'</span>)</span><br><span class="line">            <span class="comment"># tds[0].get_text(" ").split(" ")[0]也可以</span></span><br><span class="line">            ulist.append([tds[<span class="number">0</span>].contents[<span class="number">0</span>], tds[<span class="number">1</span>].string, tds[<span class="number">3</span>].string])</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printUnivList_A</span><span class="params">(ulist, num)</span>:</span></span><br><span class="line">    tplt = <span class="string">"&#123;0:^4&#125;\t&#123;1:&#123;3&#125;^12&#125;\t&#123;2:^10&#125;"</span></span><br><span class="line">    print(tplt.format(<span class="string">"排名"</span>, <span class="string">"学校名称"</span>, <span class="string">"总分"</span>, chr(<span class="number">12288</span>)))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num):</span><br><span class="line">        u = ulist[i]</span><br><span class="line">        print(tplt.format(u[<span class="number">0</span>], u[<span class="number">1</span>], u[<span class="number">2</span>], chr(<span class="number">12288</span>)))</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">instance_3</span><span class="params">()</span>:</span></span><br><span class="line">    uinfo = []</span><br><span class="line">    url = <span class="string">'http://www.zuihaodaxue.cn/zuihaodaxuepaiming2017.html'</span></span><br><span class="line">    html = getHTMLText(url)</span><br><span class="line">    fillUnivList(uinfo, html)</span><br><span class="line">    printUnivList_A(uinfo, <span class="number">20</span>)  <span class="comment"># 20 univs</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">"__main__"</span>:</span><br><span class="line">    instance_3()</span><br></pre></td></tr></table></figure>

<p>最终结果</p>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402183419220.png" alt="image-20200402183419220"></p>
<h3 id="扩展2-url改为软科排名2016"><a href="#扩展2-url改为软科排名2016" class="headerlink" title="扩展2-url改为软科排名2016"></a>扩展2-url改为软科排名2016</h3><p>将实例2中url改为软科世界大学学术排名 2016：<a href="http://www.zuihaodaxue.cn/ARWU2016.html" target="_blank" rel="noopener">http://www.zuihaodaxue.cn/ARWU2016.html</a><br>该如何修改代码？</p>
<p>可以看到没有多大的变化，只是大学名、国家\地区有些不同    </p>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402165756192.png" alt="image-20200402165756192"></p>
<p>对之前的代码稍加修改可得结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">instance_3_2</span><span class="params">()</span>:</span></span><br><span class="line">    uinfo = []</span><br><span class="line">    url = <span class="string">'http://www.zuihaodaxue.cn/ARWU2016.html'</span></span><br><span class="line">    html = getHTMLText(url)</span><br><span class="line">    soup = BeautifulSoup(html, <span class="string">"html.parser"</span>)</span><br><span class="line">    <span class="keyword">for</span> tr <span class="keyword">in</span> soup.find(<span class="string">'tbody'</span>).children:</span><br><span class="line">        <span class="keyword">if</span> isinstance(tr, bs4.element.Tag):</span><br><span class="line">            tds = tr(<span class="string">'td'</span>)</span><br><span class="line">            uinfo.append([tds[<span class="number">0</span>].string, tds[<span class="number">1</span>].a.string, tds[<span class="number">3</span>].string])</span><br><span class="line">    tplt = <span class="string">"&#123;0:^4&#125;\t&#123;1:&#123;3&#125;^12&#125;\t&#123;2:^10&#125;"</span></span><br><span class="line">    print(tplt.format(<span class="string">"排名"</span>, <span class="string">"学校名称"</span>, <span class="string">"总分"</span>, chr(<span class="number">12288</span>)))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">20</span>):</span><br><span class="line">        u = uinfo[i]</span><br><span class="line">        print(tplt.format(u[<span class="number">0</span>], u[<span class="number">1</span>], u[<span class="number">2</span>], chr(<span class="number">12288</span>)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">"__main__"</span>:</span><br><span class="line">    instance_3_2()</span><br></pre></td></tr></table></figure>

<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402170840117.png" alt="image-20200402170840117"></p>
<h2 id="3-爬取当当图书排行榜（榜单自选）"><a href="#3-爬取当当图书排行榜（榜单自选）" class="headerlink" title="3.爬取当当图书排行榜（榜单自选）"></a>3.爬取当当图书排行榜（榜单自选）</h2><p>格式：爬取结果包含但不限于[排名 书名 作者]， 注意输出格式对齐。</p>
<p>我这里爬取 <code>信息安全</code>类书籍的销量排行榜</p>
<p><a href="http://bang.dangdang.com/books/bestsellers/01.54.19.00.00.00-24hours-0-0-1-1" target="_blank" rel="noopener">http://bang.dangdang.com/books/bestsellers/01.54.19.00.00.00-24hours-0-0-1-1</a></p>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402171057952.png" alt="image-20200402171057952"></p>
<p>可以看到<code>html</code>结构如下</p>
<p>先从<code>class</code>为<code>bang_list clearfix bang_list_mode</code>中的<code>ul</code>遍历<code>li</code></p>
<p>再从<code>li</code>中找出</p>
<ul>
<li>排名</li>
<li>名字</li>
<li>现在的价格</li>
<li>之前的价格</li>
<li>链接</li>
</ul>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402171331034.png" alt="image-20200402171331034"></p>
<p>代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">instance_4</span><span class="params">()</span>:</span></span><br><span class="line">    uinfo = []</span><br><span class="line">    url = <span class="string">'http://bang.dangdang.com/books/bestsellers/01.54.19.00.00.00-24hours-0-0-1-1'</span></span><br><span class="line">    html = getHTMLText(url)</span><br><span class="line">    soup = BeautifulSoup(html, <span class="string">"html.parser"</span>)</span><br><span class="line">    <span class="comment"># print(soup.prettify())</span></span><br><span class="line">    <span class="keyword">for</span> li <span class="keyword">in</span> soup.find(<span class="string">'ul'</span>,attrs=&#123;<span class="string">"class"</span>:re.compile(<span class="string">'bang_list clearfix bang_list_mode'</span>)&#125;).children:</span><br><span class="line">        <span class="keyword">if</span> isinstance(li, bs4.element.Tag):</span><br><span class="line">            div_array = li(<span class="string">'div'</span>)</span><br><span class="line">            rank=div_array[<span class="number">0</span>].string</span><br><span class="line">            name=div_array[<span class="number">1</span>].a.img.attrs[<span class="string">'title'</span>]</span><br><span class="line">            price_n=div_array[<span class="number">6</span>].p.contents[<span class="number">1</span>].string</span><br><span class="line">            prince_before=div_array[<span class="number">6</span>].p.contents[<span class="number">3</span>].string</span><br><span class="line">            url=div_array[<span class="number">1</span>].a.attrs[<span class="string">'href'</span>]</span><br><span class="line">            uinfo.append([rank,name,price_n,prince_before,url])</span><br><span class="line">    tplt = <span class="string">"&#123;0:^3&#125;\t&#123;1:&#123;5&#125;^15&#125;\t&#123;2:^5&#125;\t&#123;3:^5&#125;\t&#123;4:^10&#125;"</span></span><br><span class="line">    print(tplt.format(<span class="string">"排名"</span>, <span class="string">"书名"</span>, <span class="string">"之前的价格"</span>,<span class="string">"当前价格"</span>,<span class="string">"URL"</span>, chr(<span class="number">12288</span>)))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">20</span>):</span><br><span class="line">        u = uinfo[i]</span><br><span class="line">        print(tplt.format(u[<span class="number">0</span>], u[<span class="number">1</span>], u[<span class="number">2</span>],u[<span class="number">3</span>],u[<span class="number">4</span>],chr(<span class="number">12288</span>)))</span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">"__main__"</span>:</span><br><span class="line"></span><br><span class="line">    instance_4()</span><br></pre></td></tr></table></figure>

<p>结果如下！！！</p>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402175720833.png" alt="image-20200402175720833"></p>
<h1 id="实验2-1-正则式"><a href="#实验2-1-正则式" class="headerlink" title="实验2.1-正则式"></a>实验2.1-正则式</h1><h2 id="介绍-1"><a href="#介绍-1" class="headerlink" title="介绍"></a>介绍</h2><p>正则表达式（Regular Expression，简写为regex或RE），使用单个字符串来描述、匹配一系列匹配某个句法规则的字符串。在很多文本编辑器里，正则表达式通常被用来检索、替换那些匹配某个模式的文本。</p>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402184401030.png" alt="image-20200402184401030"></p>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402200458302.png" alt="image-20200402200458302"></p>
<p>re库主要的方法如下</p>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402204550930.png" alt="image-20200402204550930"></p>
<p>match对象包含了关于此次匹配的信息，可以使用Match提供的可读属性或方法来获取这些信息。</p>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402204649960.png" alt="image-20200402204649960"></p>
<p>只要长度输出可能不同的，都可以通过在操作符后增加?变成最小匹配</p>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402204939305.png" alt="image-20200402204939305"></p>
<h2 id="尝试爬取淘宝商品的数据"><a href="#尝试爬取淘宝商品的数据" class="headerlink" title="尝试爬取淘宝商品的数据"></a>尝试爬取淘宝商品的数据</h2><ul>
<li><p>扫码登陆淘宝</p>
</li>
<li><p>搜索某个商品</p>
</li>
<li><p>发现商品分页的规律——如下，</p>
<p>第1页<code>https://s.taobao.com/search</code> <code>?q=airpodspro</code> <code>&amp;s=0</code></p>
<p>第2页<code>https://s.taobao.com/search</code> <code>?q=airpodspro</code> <code>&amp;s=44</code></p>
<p>第3页<code>https://s.taobao.com/search</code> <code>?q=airpodspro</code> <code>&amp;s=88</code></p>
<p>可以看出每页的s都是44累加的，这样我们想要遍历分页只需要遍历s即可</p>
</li>
</ul>
<p>由于淘宝有反爬虫机制，我们要将手动登陆后的Cookies、agent复制到header中</p>
<ul>
<li>扫码登陆淘宝</li>
<li>搜索商品，Chrome  下 F12打开审查</li>
<li>点击Network-&gt;Doc类型-&gt;search……-&gt;复制cookie、user-agent</li>
<li>将cookie、user-agent放到请求中，具体方式看代码</li>
</ul>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402215404788.png" alt="image-20200402215404788"></p>
<p>编写程序</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHTMLText</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># AFAEF728105FFA95263125A9E0A097DC</span></span><br><span class="line">        hd = &#123;<span class="string">'cookie'</span>: <span class="string">'t=31555440a71b4d3ae330f044081146f9; cna=eaagFpxdLAUCAdrFmScIIYcw; thw=cn; cookie2=1bdfd953450db1890a4960bafedf8169; v=0; _tb_token_=eefe396e49733; _samesite_flag_=true; sgcookie=Edo1lgxwoK2bRfYVahZOe; unb=2522367083; uc3=lg2=UIHiLt3xD8xYTw%3D%3D&amp;id2=UU2w7Hb9dvcsIQ%3D%3D&amp;nk2=tw%2F9XZuWLTE%3D&amp;vt3=F8dBxdAW4LSdjQGNkyg%3D; csg=dbe09bde; lgc=%5Cu518D%5Cu89C1%5Cu795E%5Cu5947; cookie17=UU2w7Hb9dvcsIQ%3D%3D; dnk=%5Cu518D%5Cu89C1%5Cu795E%5Cu5947; skt=d262960506d154ef; existShop=MTU4NTgzMjY2OQ%3D%3D; uc4=nk4=0%40tXwweg7zi7bxIxNwomsc8lmKSw%3D%3D&amp;id4=0%40U2%2F32UM%2BC1YLt9wuKmGuJsNzMVo7; tracknick=%5Cu518D%5Cu89C1%5Cu795E%5Cu5947; _cc_=VT5L2FSpdA%3D%3D; _l_g_=Ug%3D%3D; sg=%E5%A5%873f; _nk_=%5Cu518D%5Cu89C1%5Cu795E%5Cu5947; cookie1=AHnU1YHbYbkYLGQxilkANOpn3Y133DLACku%2BjBXRjNk%3D; enc=q3Gwz15Bq6QwoLkeceXsesqtD8wfeR5rLdWz%2BffQweZA9DT9jrnDbu8nmeCLcdc0X%2BE9JypMae6noiYZzph68g%3D%3D; tfstk=cEPhBo_vJJkCDiI_-HGQy2BO73GhalBEA7Pa_WoWKw4ovdFZ8sDJQKWBJNmLx7p5.; mt=ci=113_1; uc1=cookie16=URm48syIJ1yk0MX2J7mAAEhTuw%3D%3D&amp;cookie21=VFC%2FuZ9aiKCaj7AzMHh1&amp;cookie15=Vq8l%2BKCLz3%2F65A%3D%3D&amp;existShop=false&amp;pas=0&amp;cookie14=UoTUP2oWHktHHQ%3D%3D; l=dBEymxamQbBz3b0YBOfgqDezDdbOXBRflsPr9GLh3IB19u53HdBqEHweIlleI3QQEt134eKrjGibiRQeC3fRwxDDB3h2q_5xnxf..; isg=BIOD_uxF2W-mR5UgKRuxH2xxEkct-Bc6Bw5VXrVg3-JZdKOWPcinimHi7gQ6VG8y'</span></span><br><span class="line">              ,<span class="string">'user-agent'</span>: <span class="string">'Mozilla/5.0'</span>&#125;</span><br><span class="line">        r = requests.get(url, timeout=<span class="number">30</span>,headers=hd)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> r.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">""</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parsePage</span><span class="params">(ilt, html)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        plt = re.findall(<span class="string">r'\"view_price\"\:\"[\d\.]*\"'</span>, html) <span class="comment">#匹配价格</span></span><br><span class="line">        tlt = re.findall(<span class="string">r'\"raw_title\"\:\".*?\"'</span>, html)  <span class="comment">#匹配标题</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(plt)):</span><br><span class="line">            price = eval(plt[i].split(<span class="string">':'</span>)[<span class="number">1</span>])  <span class="comment">#对搜索结果进行分割，以“：”为分割点</span></span><br><span class="line">            title = eval(tlt[i].split(<span class="string">':'</span>)[<span class="number">1</span>])  <span class="comment">#eval将字符串当成有效的表达式来求值并返回计算结果</span></span><br><span class="line">            ilt.append([price, title])</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        print(<span class="string">""</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printGoodsList</span><span class="params">(ilt)</span>:</span></span><br><span class="line">    tplt = <span class="string">"&#123;:4&#125;\t&#123;:8&#125;\t&#123;:16&#125;"</span></span><br><span class="line">    print(tplt.format(<span class="string">"序号"</span>, <span class="string">"价格"</span>, <span class="string">"商品名称"</span>))</span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> g <span class="keyword">in</span> ilt:</span><br><span class="line">        count = count + <span class="number">1</span></span><br><span class="line">        <span class="comment"># print((tplt.format(count, g[0], g[1])+"\n"))</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">with</span> open(<span class="string">"taobao-airpods pro.txt"</span>, <span class="string">"a+"</span>) <span class="keyword">as</span> f:</span><br><span class="line">                f.write((tplt.format(count, g[<span class="number">0</span>], g[<span class="number">1</span>])+<span class="string">"\n"</span>)) <span class="comment"># 这句话自带文件关闭功能，不需要再写f.close()</span></span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    goods = <span class="string">'airpodspro'</span></span><br><span class="line">    depth = <span class="number">100</span></span><br><span class="line">    start_url = <span class="string">'https://s.taobao.com/search?q='</span> + goods</span><br><span class="line">    infoList = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(depth):</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            url = start_url + <span class="string">'&amp;s='</span> + str(<span class="number">44</span> * i)</span><br><span class="line">            html = getHTMLText(url)</span><br><span class="line">            <span class="comment"># print(html)</span></span><br><span class="line">            parsePage(infoList, html)</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">    printGoodsList(infoList)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">"__main__"</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<p>功能说明：</p>
<ul>
<li><code>main()</code>主程序用于遍历商品页输出</li>
<li><code>getHTMLText()</code>用于获得html</li>
<li><code>parsePage()</code>用正则式搜索商品名称和价格</li>
<li><code>printGoodsList()</code> 用于向命令行输出</li>
</ul>
<p>这里写入txt——用python向txt文件中写数据时的追加和覆盖，我们使用a+</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> open(<span class="string">"test.txt"</span>,<span class="string">"w"</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(<span class="string">"这是个测试！"</span>) <span class="comment">#这句话自带文件关闭功能，不需要再写f.close()</span></span><br><span class="line">r：以只读方式打开文件。文件的指针将会放在文件的开头。这是默认模式。</span><br><span class="line">r+：打开一个文件用于读写。文件指针将会放在文件的开头。 </span><br><span class="line">w：打开一个文件只用于写入。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。</span><br><span class="line">w+：打开一个文件用于读写。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。</span><br><span class="line">a：打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。</span><br><span class="line">a+：打开一个文件用于读写。如果该文件已存在，文件指针将会放在文件的结尾。文件打开时会是追加模式。如果该文件不存在，创建新文件用于读写。</span><br></pre></td></tr></table></figure>

<p>我爬取的是airpodspro的相关信息，爬取100页，具体的数据会存储到txt中</p>
<p>运行程序，成功</p>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402213933616.png" alt="image-20200402213933616"></p>
<p>爬取的过程中出现了编码问题</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UnicodeEncodeError: <span class="string">'gbk'</span> codec can<span class="string">'t encode character '</span>\xae<span class="string">' in position 17: illegal multibyte sequence</span></span><br></pre></td></tr></table></figure>

<p>处理一下exception就好了</p>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402222101748.png" alt="image-20200402222101748"></p>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402223510719.png" alt="image-20200402223510719"></p>
<h1 id="实验2-2-用srapy框架爬取任意网站的内容"><a href="#实验2-2-用srapy框架爬取任意网站的内容" class="headerlink" title="实验2.2-用srapy框架爬取任意网站的内容"></a>实验2.2-用srapy框架爬取任意网站的内容</h1><p>要求：（不少于50条）</p>
<h2 id="介绍-2"><a href="#介绍-2" class="headerlink" title="介绍"></a>介绍</h2><h3 id="1-Scrapy与request"><a href="#1-Scrapy与request" class="headerlink" title="1.Scrapy与request"></a>1.Scrapy与request</h3><ul>
<li>相同点：两者都可以进行页面请求和爬取，Python爬虫的两个重要技术路线两者可用性都好，文档丰富，入门简单两者都没有处理js、提交表单、应对验证码等功能（可扩展）</li>
<li>不同点：<ul>
<li>Requests 页面级爬虫，功能库，并发性考虑不足，性能较差，重点在于页面下载。定制灵活，上手十分简单 。</li>
<li>Scrapy<br>网站级爬虫 框架，并发性好，性能较高， 重点在于爬虫结构。 一般定制灵活，深度定制困难， 入门稍难。</li>
</ul>
</li>
</ul>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402222443363.png" alt="image-20200402222443363"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Engine从Spider处获得爬取请求(Request)</span><br><span class="line">Engine将爬取请求转发给Scheduler，用于调度</span><br><span class="line">Engine从Scheduler处获得下一个要爬取的请求</span><br><span class="line">Engine将爬取请求通过中间件发送给Downloader</span><br><span class="line">爬取网页后，Downloader形成响应（Response）通过中间件发给Engine</span><br><span class="line">Engine将收到的响应通过中间件发送给Spider处理 </span><br><span class="line">Spider处理响应后产生爬取项（scraped Item）和新的爬取请求（Requests）给Engine</span><br><span class="line">Engine将爬取项发送给Item Pipeline（框架出口）</span><br><span class="line">Engine将爬取请求发送给Scheduler</span><br></pre></td></tr></table></figure>

<h3 id="2-安装"><a href="#2-安装" class="headerlink" title="2.安装"></a>2.安装</h3><ul>
<li><p>安装lxml： pip install lxml</p>
</li>
<li><p>下载对应版本的Twisted</p>
<p>我下面的方法没成功，是在pycharm下下载的</p>
<p>%%%%%%%%%%%%%%%%%%%%</p>
<p>++++++++++++++++++++++++</p>
<p>​       <a href="http://www.lfd.uci.edu/~gohlke/pythonlibs/#twisted" target="_blank" rel="noopener">http://www.lfd.uci.edu/~gohlke/pythonlibs/#twisted</a> </p>
<p>​        <img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402222827956.png" alt="image-20200402222827956"></p>
<p>​       pip3 install C:\Users\78290\Desktop\Twisted-20.3.0-cp38-cp38-win_amd64.whl</p>
<p>​        (下载好的twisted模块的whl文件路径)</p>
<p>​    %%%%%%%%%%%%%%%%%%</p>
</li>
<li><p>安装scrapy：pip install scrapy</p>
</li>
<li><p>安装关联模块pypiwin32：pip install pypiwin32 </p>
</li>
</ul>
<h3 id="3-创建一个scrapy"><a href="#3-创建一个scrapy" class="headerlink" title="3.创建一个scrapy"></a>3.创建一个scrapy</h3><p>Scrapy常用命令</p>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402224714359.png" alt="image-20200402224714359"></p>
<p>1.创建项目：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject tutorial</span><br></pre></td></tr></table></figure>

<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402225249765.png" alt="image-20200402225249765"></p>
<p>2.定义Item</p>
<p>编辑 tutorial 目录中的 items.py 文件:</p>
<p>3.编写spider </p>
<p>Spider是用户编写用于从单个网站(或者一些网站)爬取数据的类。其包含了一个用于下载的初始URL，如何跟进网页中的链接以及如何分析页面中的内容， 提取生成 item 的方法。<br>为了创建一个Spider，必须继承 scrapy.Spider 类， 且定义三个属性：</p>
<ul>
<li>name: 用于区别Spider。 该名字必须是唯一的，不可以为不同的Spider设定相同的名字。</li>
<li>start_urls: 包含了Spider在启动时进行爬取的url列表。 因此，第一个被获取到的页面将是其中之一。 后续的URL则从初始的URL获取到的数据中提取。</li>
<li>parse() 是spider的一个方法。 被调用时，每个初始URL完成下载后生成的 Response 对象将会作为唯一的参数传递给该函数。 该方法负责解析返回的数据(response data)，提取数据(生成item)以及生成需要进一步处理的URL的 Request 对象。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">在项目中生成 spider 文件的两种方法:</span><br><span class="line">命令行输入 Scrapy genspider domain domain.com</span><br><span class="line">tutorial&#x2F;spiders&#x2F;目录下创建domain.py</span><br></pre></td></tr></table></figure>

<p>4.执行spider</p>
<p>进入项目的根目录，执行下列命令启动spider    </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl w3school</span><br></pre></td></tr></table></figure>

<p>5.提取item</p>
<p>scrapy支持如下库</p>
<ul>
<li>Beautiful Soup</li>
<li>Lxml</li>
<li>Re</li>
<li>Xpath</li>
<li>CSS</li>
</ul>
<h2 id="豆瓣电影-top250"><a href="#豆瓣电影-top250" class="headerlink" title="豆瓣电影 top250"></a>豆瓣电影 top250</h2><p>创建项目</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy genspider douban_movie &quot;douban_movie.com&quot;</span><br></pre></td></tr></table></figure>

<p>进入spider新建spider</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd douban</span><br><span class="line">cd douban</span><br><span class="line">scrapy crawl douban_movie</span><br></pre></td></tr></table></figure>

<p>项目结构</p>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402235349247.png" alt="image-20200402235349247"></p>
<p>代码如下</p>
<p>douban_movie.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> douban.items <span class="keyword">import</span> DoubanItem</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DoubanMovieSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'douban_movie'</span></span><br><span class="line">    allowed_domains = [<span class="string">'movie.douban.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'https://movie.douban.com/j/chart/top_list?type=11&amp;interval_id=100%3A90&amp;action=&amp;start=0&amp;limit=20'</span>]</span><br><span class="line">    offset = <span class="number">0</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        item = DoubanItem()</span><br><span class="line">        content_list = json.loads(response.body.decode())</span><br><span class="line">        <span class="keyword">if</span> (content_list == []):</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="keyword">for</span> content <span class="keyword">in</span> content_list:</span><br><span class="line">            item[<span class="string">'title'</span>] = content[<span class="string">'title'</span>]</span><br><span class="line">            item[<span class="string">'url'</span>] = content[<span class="string">'url'</span>]</span><br><span class="line">            <span class="keyword">yield</span> item</span><br><span class="line">        self.offset += <span class="number">20</span> <span class="comment">#拼接分页请求链接</span></span><br><span class="line">        url = <span class="string">'https://movie.douban.com/j/chart/top_list?type=11&amp;interval_id=100%3A90&amp;action=&amp;start='</span>+str(self.offset) + <span class="string">'&amp;limit=20'</span></span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(url=url,callback=self.parse)</span><br></pre></td></tr></table></figure>

<p>items.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DoubanItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    title = scrapy.Field()</span><br><span class="line">    url = scrapy.Field()</span><br></pre></td></tr></table></figure>

<p>pipelines.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DoubanPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self,spider)</span>:</span></span><br><span class="line">        self.file = open(<span class="string">"douban.json"</span>,<span class="string">"w"</span>)</span><br><span class="line">        self.num = <span class="number">0</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        self.num+=<span class="number">1</span></span><br><span class="line">        content = json.dumps(dict(item),ensure_ascii=<span class="literal">False</span>)+<span class="string">'\n'</span></span><br><span class="line">        self.file.write(content)</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self,spider)</span>:</span></span><br><span class="line">        print(<span class="string">'一共保存了'</span>+str(self.num)+<span class="string">'条数据'</span>)</span><br><span class="line">        self.file.close()</span><br></pre></td></tr></table></figure>

<p>setting.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">BOT_NAME = <span class="string">'douban'</span></span><br><span class="line"></span><br><span class="line">SPIDER_MODULES = [<span class="string">'douban.spiders'</span>]</span><br><span class="line">NEWSPIDER_MODULE = <span class="string">'douban.spiders'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Crawl responsibly by identifying yourself (and your website) on the user-agent</span></span><br><span class="line">USER_AGENT = <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.15 Safari/537.36'</span></span><br></pre></td></tr></table></figure>

<p>启动</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl douban_movie</span><br></pre></td></tr></table></figure>

<p>成功   保存为douban.json</p>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200402235614155.png" alt="image-20200402235614155"></p>
<p>参考链接：</p>
<ol>
<li><p><a href="https://www.jianshu.com/p/ac9547e332da" target="_blank" rel="noopener">https://www.jianshu.com/p/ac9547e332da</a></p>
</li>
<li><p><a href="http://www.scrapyd.cn/" target="_blank" rel="noopener">scrapy中文网</a></p>
</li>
</ol>
<h1 id="实验3-使用GooSeeker爬取数据"><a href="#实验3-使用GooSeeker爬取数据" class="headerlink" title="实验3-使用GooSeeker爬取数据"></a>实验3-使用GooSeeker爬取数据</h1><h2 id="介绍-3"><a href="#介绍-3" class="headerlink" title="介绍"></a>介绍</h2><p>​     GooSeeker是一个采用云计算架构的网页数据抽取工具包，能根据用户的指导，从网页上抓取需要的文本，并输出按一定结构输出提取结果文件（XML文件）</p>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200403123135206.png" alt="image-20200403123135206"></p>
<h2 id="实例-知乎热榜爬取"><a href="#实例-知乎热榜爬取" class="headerlink" title="实例-知乎热榜爬取"></a>实例-知乎热榜爬取</h2><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>​    首先从官方网站下载安装包，在主界面选择“下载爬虫”的下载方案比较方便。安装好软件后，新用户需要在集搜客网站上注册账号，用于之后登录集搜客软件。</p>
<h3 id="1-制作采集规则"><a href="#1-制作采集规则" class="headerlink" title="1.制作采集规则"></a>1.制作采集规则</h3><ol>
<li><p>打开MS谋数机</p>
</li>
<li><p>输入目标抓取网站的网址，命名规则主题名。</p>
</li>
</ol>
<p>第一步：在MS谋数机的“网址栏”，输入想要进行爬虫抓取的网页的网址，然后回车进行加载，可以在MS谋数机下方的“浏览器”窗口看到页面显示。</p>
<p>第二步：页面加载完后，在右边的“工作台”中的“命名主题”下方的“主题名”栏处输入自定义的主题名，这里我命名为“zhihu-rebang”，然后点击旁边的“查看”按钮，测试你起的名字是否已被占用，如果提示“该名可以使用”则命名成功。</p>
<h3 id="2-新建整理箱"><a href="#2-新建整理箱" class="headerlink" title="2.新建整理箱"></a>2.新建整理箱</h3><p>第一步：点击右方的“工作台”中的“创建规则”，点击“新建”按钮，在弹出的窗口中输入想要命名的整理箱名称。这里我命名为“rebang”。</p>
<p>第二步：在整理箱中添加抓取内容。右击整理箱名称选择“添加-包含”，这里我先添加“热榜名”，继续添加的话，右击“热榜名”选择“添加-其后”，添加“热榜简介”。</p>
<p>第三步：整理箱中必须有一个是“关键内容”，选择一个抓取内容设为“关键内容”，这里我吧“热榜名”勾选为“关键内容”。</p>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200403132103024.png" alt="image-20200403132103024"></p>
<h3 id="3-进行内容映射"><a href="#3-进行内容映射" class="headerlink" title="3.进行内容映射"></a>3.进行内容映射</h3><p>第一步：在“浏览器”窗口中点击想要获取的内容，比如现在要获取哪个内容，就在那个区域进行鼠标点击，这时候MS谋数台会自动定位其在HTML中结点的位置。</p>
<p>第二步：展开一个节点，因为“热榜名”是一个H2所以找到H2标签。</p>
<p>第三步：右击这个text，选择“内容映射-热榜名”。</p>
<p>第四步：后面的内容映射同第三步。</p>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200403125234819.png" alt="image-20200403125234819"></p>
<h3 id="4-使用样例复制"><a href="#4-使用样例复制" class="headerlink" title="4.使用样例复制"></a>4.使用样例复制</h3><p>由于评论和评论之间是相同结构的数据，我们上一步只是完成了一个评论条目的抓取，想要抓取更多的评论就需要进行样例复制。</p>
<p>第一步：点击整理箱名称，即“rebang”。</p>
<p>第二步：勾选右侧方的“启用”，开启样例复制功能。</p>
<p>第三步：分别找到第一条热榜名和第二条热榜名对应的节点。</p>
<p>第四步：右击第一条评论对应结点，选择“样例复制映射–第一个”。</p>
<p>第五步：右击第二条评论对应结点，选择“样例复制映射–第二个”。</p>
<p>可以点击右侧的“测试”按钮对当前的规则进行测试，看到的结果是不是想要抓取的内容。</p>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200403125255689.png" alt="image-20200403125255689"></p>
<p>第二个样例复制映射</p>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200403125250180.png" alt="image-20200403125250180"></p>
<p>测试-&gt;输出</p>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200403125309634.png" alt="image-20200403125309634"></p>
<h3 id="5-创建记号线索"><a href="#5-创建记号线索" class="headerlink" title="5.创建记号线索"></a>5.创建记号线索</h3><p>由于评论有很多页，所以我们要解决抓取数据的时候翻页的问题，需要创建一个“记号线索”。</p>
<p>但是知乎热榜并没有下一页，所以暂时不用</p>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200403125858495.png" alt="5"></p>
<h3 id="6-MS打数机存规则"><a href="#6-MS打数机存规则" class="headerlink" title="6.MS打数机存规则"></a>6.MS打数机存规则</h3><p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200403130137855.png" alt="image-20200403130137855"></p>
<h3 id="7-打开DS打数机爬取"><a href="#7-打开DS打数机爬取" class="headerlink" title="7.打开DS打数机爬取"></a>7.打开DS打数机爬取</h3><p>在gooseeker里打开或MS数谋机中导航打开</p>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200403130202413.png" alt="image-20200403130202413">    </p>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200403130328282.png" alt="image-20200403130328282"></p>
<p>选择任务“zhihu-rebang”-&gt;单搜</p>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200403132206171.png" alt="image-20200403132206171"></p>
<p>单搜完之后，数据默认存储在下面的路径</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\用户名\DataScraperWorks\任务名</span><br></pre></td></tr></table></figure>

<p>在爬取完后打开</p>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200403135744961.png" alt="image-20200403135744961"></p>
<h3 id="8-导出xlsx数据"><a href="#8-导出xlsx数据" class="headerlink" title="8.导出xlsx数据"></a>8.导出xlsx数据</h3><p>在会员中心、数据管理中导入存储在本地的爬取数据</p>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200403133433216.png" alt="image-20200403133433216"></p>
<p>导出为xlsx数据，成功！</p>
<p><img src="/2020/03/25/2020-03-25-information-security-exp-1/image-20200403133608712.png" alt="image-20200403133608712"></p>
<p>参考链接：</p>
<p><a href="https://www.jianshu.com/p/62bb53e07544" target="_blank" rel="noopener">https://www.jianshu.com/p/62bb53e07544</a></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ol>
<li><p>这次的实验学到了爬虫的python相关库、工具，学习了正则式等知识</p>
</li>
<li><p>BeautifulSoup库这种自己操作的让我感觉比较轻松，但是srapy、gooseeker没有弄的太深，只学了皮毛。但是按scrap明显比较成熟，有各种配置可以使用，以后还是得学一手。</p>
</li>
<li><p>在学爬虫之前一直对网络很恐惧，自己不能掌握它，后来学了计网，其实也不过如此。</p>
</li>
<li><p>总的来说这次实验基本都完成了，在学完计网之后虽然理解了原理，但是一直没有实操。这次的实验给了我很多场景去学习，学到了很多。</p>
</li>
</ol>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/%E5%AE%9E%E9%AA%8C/" rel="tag"><i class="fa fa-tag"></i> 实验</a>
          
            <a href="/tags/%E4%BF%A1%E6%81%AF%E5%86%85%E5%AE%B9%E5%AE%89%E5%85%A8/" rel="tag"><i class="fa fa-tag"></i> 信息内容安全</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/03/22/2020-03-22-plan-A/" rel="next" title="2020-3-22-plan-A">
                <i class="fa fa-chevron-left"></i> 2020-3-22-plan-A
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/04/02/2020-04-02-inforamtion-security-exp-2/" rel="prev" title="信息内容安全实验2">
                信息内容安全实验2 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div id="gitalk-container">
	</div>	

  




        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpg"
                alt="ColaLinN" />
            
              <p class="site-author-name" itemprop="name">ColaLinN</p>
              <p class="site-description motion-element" itemprop="description">集中一点 登峰造极</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">23</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">18</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">27</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/ColaLinN" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:shenqiaaa@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#目录"><span class="nav-text">目录</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#实验环境"><span class="nav-text">实验环境</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#实验1-1-requests库"><span class="nav-text">实验1.1-requests库</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#原理"><span class="nav-text">原理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-获取状态码"><span class="nav-text">1.获取状态码</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-使用post-方法"><span class="nav-text">2.使用post()方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-实例1-2-3-4"><span class="nav-text">3.实例1&#x2F;2&#x2F;3&#x2F;4</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-亚马逊网站商品页面爬取"><span class="nav-text">1-亚马逊网站商品页面爬取</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-搜索引擎搜索关键词提交"><span class="nav-text">2-搜索引擎搜索关键词提交</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-网络图片的爬取和存储"><span class="nav-text">3-网络图片的爬取和存储</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-ip地址的查询"><span class="nav-text">4-ip地址的查询</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#实验1-2-BeautifulSoup库"><span class="nav-text">实验1.2-BeautifulSoup库</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#介绍"><span class="nav-text">介绍</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#实验要求"><span class="nav-text">实验要求</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-爬取百度搜索风云榜"><span class="nav-text">1-爬取百度搜索风云榜</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-爬取中国大学排行榜-扩展"><span class="nav-text">2-爬取中国大学排行榜+扩展</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#扩展1-url改为2017"><span class="nav-text">扩展1-url改为2017</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#扩展2-url改为软科排名2016"><span class="nav-text">扩展2-url改为软科排名2016</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-爬取当当图书排行榜（榜单自选）"><span class="nav-text">3.爬取当当图书排行榜（榜单自选）</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#实验2-1-正则式"><span class="nav-text">实验2.1-正则式</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#介绍-1"><span class="nav-text">介绍</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#尝试爬取淘宝商品的数据"><span class="nav-text">尝试爬取淘宝商品的数据</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#实验2-2-用srapy框架爬取任意网站的内容"><span class="nav-text">实验2.2-用srapy框架爬取任意网站的内容</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#介绍-2"><span class="nav-text">介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-Scrapy与request"><span class="nav-text">1.Scrapy与request</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-安装"><span class="nav-text">2.安装</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-创建一个scrapy"><span class="nav-text">3.创建一个scrapy</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#豆瓣电影-top250"><span class="nav-text">豆瓣电影 top250</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#实验3-使用GooSeeker爬取数据"><span class="nav-text">实验3-使用GooSeeker爬取数据</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#介绍-3"><span class="nav-text">介绍</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#实例-知乎热榜爬取"><span class="nav-text">实例-知乎热榜爬取</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#安装"><span class="nav-text">安装</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-制作采集规则"><span class="nav-text">1.制作采集规则</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-新建整理箱"><span class="nav-text">2.新建整理箱</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-进行内容映射"><span class="nav-text">3.进行内容映射</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-使用样例复制"><span class="nav-text">4.使用样例复制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-创建记号线索"><span class="nav-text">5.创建记号线索</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-MS打数机存规则"><span class="nav-text">6.MS打数机存规则</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-打开DS打数机爬取"><span class="nav-text">7.打开DS打数机爬取</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-导出xlsx数据"><span class="nav-text">8.导出xlsx数据</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#总结"><span class="nav-text">总结</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ColaLinN</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">站点总字数&#58;</span>
    
    <span title="站点总字数">45.2k</span>
  
</div>







<div>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<span id="busuanzi_container_site_pv" style='display:none'>
    本站总访问量 <span id="busuanzi_value_site_pv"></span> 次
    <span class="post-meta-divider">|</span>
</span>
<span id="busuanzi_container_site_uv" style='display:none'>
    有<span id="busuanzi_value_site_uv"></span>人访问
</span>
</div>



<!--添加网站的运行时间-->
<span id="sitetime"></span>
<script language=javascript>
	function siteTime(){
		window.setTimeout("siteTime()", 1000);
		var seconds = 1000;
		var minutes = seconds * 60;
		var hours = minutes * 60;
		var days = hours * 24;
		var years = days * 365;
		var today = new Date();
		var todayYear = today.getFullYear();
		var todayMonth = today.getMonth()+1;
		var todayDate = today.getDate();
		var todayHour = today.getHours();
		var todayMinute = today.getMinutes();
		var todaySecond = today.getSeconds();
		/* Date.UTC() -- 返回date对象距世界标准时间(UTC)1970年1月1日午夜之间的毫秒数(时间戳)
		year - 作为date对象的年份，为4位年份值
		month - 0-11之间的整数，做为date对象的月份
		day - 1-31之间的整数，做为date对象的天数
		hours - 0(午夜24点)-23之间的整数，做为date对象的小时数
		minutes - 0-59之间的整数，做为date对象的分钟数
		seconds - 0-59之间的整数，做为date对象的秒数
		microseconds - 0-999之间的整数，做为date对象的毫秒数 */
		var t1 = Date.UTC(2020,01,15,19,00,00); //北京时间2018-2-13 00:00:00
		var t2 = Date.UTC(todayYear,todayMonth,todayDate,todayHour,todayMinute,todaySecond);
		var diff = t2-t1;
		var diffYears = Math.floor(diff/years);
		var diffDays = Math.floor((diff/days)-diffYears*365);
		var diffHours = Math.floor((diff-(diffYears*365+diffDays)*days)/hours);
		var diffMinutes = Math.floor((diff-(diffYears*365+diffDays)*days-diffHours*hours)/minutes);
		var diffSeconds = Math.floor((diff-(diffYears*365+diffDays)*days-diffHours*hours-diffMinutes*minutes)/seconds);
		document.getElementById("sitetime").innerHTML=" 已安全运行"+/*diffYears+" 年 "+*/diffDays+" 天 "+diffHours+" 小时 "+diffMinutes+" 分钟 "+diffSeconds+" 秒";
	}/*因为建站时间还没有一年，就将之注释掉了。需要的可以取消*/
	siteTime();
</script>


        







        
      </div>
    </footer>

    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
  <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
   <script type="text/javascript">
        var gitalk = new Gitalk({
          clientID: '7dd0e4dd1112b4f6ac75',
          clientSecret: '5f52c7a06abafb34741cd6468191b708c1f166b9',
          repo: 'ColaLinN.github.io',
          owner: 'ColaLinN',
          admin: ['ColaLinN'],
          id: location.pathname,
          distractionFreeMode: 'true'
        })
        gitalk.render('gitalk-container')           
       </script>


  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  

  

    <!-- 代码块复制功能 -->
  <script type="text/javascript" src="/js/src/clipboard.min.js"></script>  
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/assets/z16.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false});</script></body>
</html>
